{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e88e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8155c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.common import DetectMultiBackend\n",
    "from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
    "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
    "                           increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh)\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.torch_utils import select_device, time_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b0696c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def load_yolo_predictor(device=0, \n",
    "                        dnn=False, \n",
    "                        data=\"\",\n",
    "                        weights=[]):\n",
    "    device = select_device(device)\n",
    "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data)\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def run(\n",
    "       model,\n",
    "       source=\"\",\n",
    "       imgsz=(1024, 1024), \n",
    "       conf_thres=0.25,\n",
    "       iou_thres=0.4,\n",
    "       max_det=1000,\n",
    "       device=0, \n",
    "       view_img=False, \n",
    "       save_txt=False,\n",
    "       save_conf=False,\n",
    "       save_crop=False,\n",
    "       nosave=False,\n",
    "       classes=None,\n",
    "       agnostic_nms=False,\n",
    "       augment=False,\n",
    "       visualize=False,\n",
    "       update=False,\n",
    "       project=\"/home/sentic/Documents/data/storage/Madu_stuff/expi1\", \n",
    "       name=\"expi1\",\n",
    "       exist_ok=False,\n",
    "       line_thickness=3,\n",
    "       hide_labels=False,\n",
    "       hide_conf=False,\n",
    "       half=False,\n",
    "       ):\n",
    "    source = str(source)\n",
    "    save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
    "    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)\n",
    "    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)\n",
    "    if is_url and is_file:\n",
    "        source = check_file(source)  # download\n",
    "\n",
    "    # save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run\n",
    "    save_dir = Path(project) / name\n",
    "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
    "    \n",
    "    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "    bs = 1  # batch_size\n",
    "    \n",
    "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
    "    model.warmup(imgsz=(1, 3, *imgsz), half=half)  # warmup\n",
    "    dt, seen = [0.0, 0.0, 0.0], 0\n",
    "    for path, im, im0s, vid_cap, s in dataset:\n",
    "        t1 = time_sync()\n",
    "#         im = cv2.imread(\"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png\")\n",
    "#         im = np.transpose(im, (2, 0, 1))\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "        pred = model(im, augment=augment, visualize=visualize)\n",
    "        t3 = time_sync()\n",
    "        dt[1] += t3 - t2\n",
    "        \n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "        dt[2] += time_sync() - t3\n",
    "        for i, det in enumerate(pred):  # per image\n",
    "            seen += 1\n",
    "            p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "            from matplotlib import pyplot as plt\n",
    "            p = Path(p)  # to Path\n",
    "            save_path = str(save_dir / p.name)  # im.jpg\n",
    "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt\n",
    "            s += '%gx%g ' % im.shape[2:]  # print string\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "            annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    if save_img or save_crop or view_img:  # Add bbox to image\n",
    "                        c = int(cls)  # integer class\n",
    "                        label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')\n",
    "                        annotator.box_label(xyxy, label, color=colors(c, True))\n",
    "            LOGGER.info(f'{s}Done. ({t3 - t2:.3f}s)')\n",
    "            im0 = annotator.result()\n",
    "            if view_img:\n",
    "                cv2.imshow(str(p), im0)\n",
    "                cv2.waitKey(1)  # 1 millisecond\n",
    "            if save_img:\n",
    "                if dataset.mode == 'image':\n",
    "                    cv2.imwrite(save_path, im0)    \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1365fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_01_SGD//weights/best.pt\",\n",
    "           \"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_02_SGD//weights/best.pt\",\n",
    "           \"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_03_SGD//weights/best.pt\",\n",
    "           \"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_01_SGD//weights/best.pt\",\n",
    "           \"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_02_SGD//weights/best.pt\",\n",
    "           \"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_03_SGD//weights/best.pt\",\n",
    "           \"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_01_SGD//weights/best.pt\",\n",
    "           \"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_02_SGD//weights/best.pt\",\n",
    "           \"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_03_SGD//weights/best.pt\"\n",
    "          ]\n",
    "data = \"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/nodule01.yaml\"\n",
    "source = \"/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png\"\n",
    "augment = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780dc467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ v6.0-192-g436ffc4 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11019MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86173414 parameters, 0 gradients, 204.0 GFLOPs\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86173414 parameters, 0 gradients, 204.0 GFLOPs\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86173414 parameters, 0 gradients, 204.0 GFLOPs\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86173414 parameters, 0 gradients, 204.0 GFLOPs\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86173414 parameters, 0 gradients, 204.0 GFLOPs\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86173414 parameters, 0 gradients, 204.0 GFLOPs\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86173414 parameters, 0 gradients, 204.0 GFLOPs\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86173414 parameters, 0 gradients, 204.0 GFLOPs\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86173414 parameters, 0 gradients, 204.0 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble created with ['/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_01_SGD//weights/best.pt', '/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_02_SGD//weights/best.pt', '/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_03_SGD//weights/best.pt', '/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_01_SGD//weights/best.pt', '/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_02_SGD//weights/best.pt', '/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_03_SGD//weights/best.pt', '/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_01_SGD//weights/best.pt', '/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_02_SGD//weights/best.pt', '/home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/NODULE_COMPETITION/YOLOV5/yolov5/runs/train/exp_1024_03_SGD//weights/best.pt']\n",
      "\n",
      "WARNING: --img-size (1024, 1024) must be multiple of max stride 32, updating to [1024, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png: 1024x1024 Done. (1.066s)\n"
     ]
    }
   ],
   "source": [
    "model = load_yolo_predictor(data=data,\n",
    "                           weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3fd0df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size (1024, 1024) must be multiple of max stride 32, updating to [1024, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png: 1024x1024 Done. (1.085s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size (1024, 1024) must be multiple of max stride 32, updating to [1024, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png: 1024x1024 Done. (1.090s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size (1024, 1024) must be multiple of max stride 32, updating to [1024, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png: 1024x1024 Done. (1.094s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size (1024, 1024) must be multiple of max stride 32, updating to [1024, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png: 1024x1024 Done. (1.093s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size (1024, 1024) must be multiple of max stride 32, updating to [1024, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png: 1024x1024 Done. (1.095s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size (1024, 1024) must be multiple of max stride 32, updating to [1024, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png: 1024x1024 Done. (1.098s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size (1024, 1024) must be multiple of max stride 32, updating to [1024, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png: 1024x1024 Done. (1.098s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size (1024, 1024) must be multiple of max stride 32, updating to [1024, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png: 1024x1024 Done. (1.101s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size (1024, 1024) must be multiple of max stride 32, updating to [1024, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png: 1024x1024 Done. (1.102s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size (1024, 1024) must be multiple of max stride 32, updating to [1024, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/sentic/Documents/data/storage/Madu_stuff/ALL_CODE/Madu/images/n1134.png: 1024x1024 Done. (1.104s)\n"
     ]
    }
   ],
   "source": [
    "run(model=model, \n",
    "    source=source,\n",
    "    augment=augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
